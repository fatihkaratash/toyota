# ğŸš€ Toyota Forex Real-Time Data Processing System

<div align="center">

![Java](https://img.shields.io/badge/Java-21-orange)
![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.2-green)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-7.5-blue)
![Docker](https://img.shields.io/badge/Docker-Compose-blue)
![OpenSearch](https://img.shields.io/badge/OpenSearch-2.11-yellow)

*Enterprise-grade real-time forex data processing pipeline with microservices architecture*

</div>
<!-- Screenshot eklemek iÃ§in -->
![System Overview](.github/images/system-overview.png)

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Project Overview](#-project-overview)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“¦ Services](#-services)
- [ğŸ”§ Configuration](#-configuration)
- [ğŸ“Š Monitoring & Dashboards](#-monitoring--dashboards)
- [ğŸ› Troubleshooting](#-troubleshooting)
- [ğŸ“š Documentation](#-documentation)

---

## ğŸ¯ Project Overview

A comprehensive **real-time forex data processing system** built with microservices architecture. The system collects forex rates from multiple sources (REST API & TCP), processes them through a sophisticated calculation pipeline, and stores results in multiple databases for analysis and monitoring.

### âœ¨ Key Features

- ğŸ”„ **Real-time Data Processing** - Live forex rate collection and processing
- ğŸ—ï¸ **Microservices Architecture** - 5+ independent, scalable services  
- ğŸ“Š **Multi-Storage Strategy** - PostgreSQL, Redis cache, OpenSearch indexing
- ğŸ” **Advanced Monitoring** - Real-time dashboards with Kibana
- ğŸ§® **Smart Calculations** - AVG and CROSS rate calculations with pipeline processing
- ğŸ³ **Containerized Deployment** - Full Docker Compose orchestration
- ğŸ“ˆ **Pipeline Tracking** - End-to-end transaction tracking with unique pipeline IDs

---

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    subgraph "Data Sources"
        REST[REST Rate Provider<br/>:8080]
        TCP[TCP Rate Provider<br/>:8081]
    end
    
    subgraph "Core Processing"
        MAIN[Main Application<br/>Coordinator + Calculator<br/>:8082]
        REDIS[(Redis Cache<br/>:6379)]
    end
    
    subgraph "Message Streaming"
        KAFKA[Apache Kafka<br/>:9092]
    end
    
    subgraph "Data Storage"
        PG[(PostgreSQL<br/>:5433)]
        OS[(OpenSearch<br/>:9200)]
    end
    
    subgraph "Monitoring"
        KIBANA[Kibana Dashboard<br/>:5601]
        FILEBEAT[Filebeat<br/>Log Aggregation]
    end
    
    REST --> MAIN
    TCP --> MAIN
    MAIN --> REDIS
    MAIN --> KAFKA
    KAFKA --> PG
    KAFKA --> OS
    FILEBEAT --> OS
    OS --> KIBANA
```

### ğŸ”„ Data Flow

1. **Collection**: REST/TCP providers generate live forex rates
2. **Coordination**: Main application coordinates data flow and calculations  
3. **Processing**: Real-time pipeline calculates AVG/CROSS rates
4. **Streaming**: Kafka distributes processed data to consumers
5. **Storage**: PostgreSQL (persistence) + OpenSearch (analytics)
6. **Monitoring**: Kibana dashboards for real-time insights


## ğŸš€ Quick Start

### Prerequisites

- ğŸ³ **Docker & Docker Compose** (v20+)
- ğŸ’» **8GB+ RAM** recommended
- ğŸŒ **Ports**: 5601, 8080-8082, 9092, 9200, 6379, 5433

### âš¡ One-Command Setup

```bash
# 1. Clone the repository
git clone https://github.com/fatihkaratash/toyota.git
cd toyota

# 2. Create environment file
cp .env.example .env

# 3. Start the entire system
docker-compose up --build -d

# 4. Wait for services to initialize (2-3 minutes)
docker-compose ps
```

### âœ… Verify Installation

```bash
# Check all services are running
docker-compose ps

# Expected output: 8 services running
# âœ… rest-rate-provider      Up    0.0.0.0:8080->8080/tcp
# âœ… tcp-rate-provider       Up    0.0.0.0:8081->8081/tcp  
# âœ… main-application        Up    0.0.0.0:8082->8082/tcp
# âœ… kafka                   Up    0.0.0.0:9092->9092/tcp
# âœ… redis                   Up    0.0.0.0:6379->6379/tcp
# âœ… postgres               Up    0.0.0.0:5433->5432/tcp
# âœ… opensearch             Up    0.0.0.0:9200->9200/tcp
# âœ… dashboard                 Up    0.0.0.0:5601->5601/tcp
```

---

## ğŸ“¦ Services

| Service | Port | Description | Health Check |
|---------|------|-------------|--------------|
| ğŸŒ **REST Provider** | 8080 | HTTP forex rate API | `curl http://localhost:8080/` |
| ğŸ”Œ **TCP Provider** | 8081 | TCP socket rate streaming | `docker logs tcp-rate-provider` |
| ğŸ§  **Main Application** | 8082 | Coordinator & Calculator | `curl http://localhost:8082/actuator/health` |
| ğŸ“¨ **Kafka** | 29092 | Message streaming | `docker exec kafka kafka-topics --list --bootstrap-server localhost:29092` |
| âš¡ **Redis** | 6379 | High-speed cache | `docker exec redis redis-cli ping` |
| ğŸ—„ï¸ **PostgreSQL** | 5433 | Rate persistence | `docker exec postgres pg_isready` |
| ğŸ” **OpenSearch** | 9200 | Search & analytics | `curl http://localhost:9200/_cluster/health` |
| ğŸ“Š **Kibana** | 5601 | Monitoring dashboard | `curl http://localhost:5601/api/status` |

---

## ğŸ”§ Configuration

### Environment Variables (.env)

```env
# Database Configuration
POSTGRES_USER=postgres
POSTGRES_PASSWORD=pgadmin
POSTGRES_DB=toyota_rates

# Provider Authentication
REST_PROVIDER_USER=admin
REST_PROVIDER_PASSWORD=admin123
TCP_PROVIDER_USER=tcpuser
TCP_PROVIDER_PASSWORD=tcp123?

# Market Trend Configuration
MARKET_TREND_INITIAL_MODE=NEUTRAL
MARKET_TREND_INITIAL_STRENGTH=0.5
TREND_REDIS_POLL_INTERVAL_SECONDS=10

# Processing Configuration
MAX_RETRY_ATTEMPTS=3
INITIAL_RETRY_DELAY_MS=1000
RETRY_BACKOFF_MULTIPLIER=2.0
READ_TIMEOUT_SECONDS=30
```

### ğŸ›ï¸ Advanced Configuration

- **Kafka Topics**: Auto-created on startup
- **Database Schema**: Auto-migrated with Flyway
- **OpenSearch Indices**: Auto-configured by consumers
- **Calculation Rules**: Defined in `main-application/src/main/resources/calculation-config.json`

---

## ğŸ“Š Monitoring & Dashboards

### ğŸ”¥ opensearch Dashboards

Access OpenSearch at **http://localhost:5601**
<!-- Dashboard screenshot -->
![Dashboard Screenshot](.github/images/dashboard-screenshot.png)

#### ğŸ“ˆ Pre-configured Dashboards:

1. **Real-time Rates** - Live forex rate monitoring
2. **Pipeline Tracking** - End-to-end transaction flow
3. **System Health** - Service performance metrics
4. **Error Analysis** - Failed transactions and alerts

#### ğŸ” Index Patterns:

```bash
# Create these index patterns in Kibana:
financial-simple-rates     # Clean user-facing rates
financial-raw-rates        # Raw provider data  
financial-calculated-rates # AVG/CROSS calculations
financial-logs-*          # Application logs
```

### ğŸ”§ Data Inspection Tools

```bash
# PostgreSQL Database
docker exec -it postgres psql -U postgres -d toyota_rates
# Commands: \dt, SELECT * FROM rates LIMIT 10;

# Redis Cache
docker exec -it redis redis-cli
# Commands: KEYS *, GET toyota_rates:calc:EURUSD_AVG

# Kafka Topics
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:29092 \
  --topic financial-simple-rates --from-beginning

# OpenSearch Indices
curl "http://localhost:9200/financial-simple-rates/_search?pretty"
```

---

## ğŸ› Troubleshooting

### ğŸš¨ Common Issues

<details>
<summary><b>Services fail to start</b></summary>

```bash
# Check system resources
docker system df
docker system prune -f

# Restart problematic services
docker-compose restart main-application
docker-compose logs main-application
```
</details>

<details>
<summary><b>No data in dashboards</b></summary>

```bash
# Verify data flow
docker logs main-application | grep "Pipeline"
docker logs kafka-consumer | grep "processed"

# Check Kafka topics
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
```
</details>

<details>
<summary><b>Memory issues</b></summary>

```bash
# Reduce memory usage in docker-compose.yml
# OpenSearch: OPENSEARCH_JAVA_OPTS=-Xms256m -Xmx256m
# Kafka: KAFKA_HEAP_OPTS=-Xmx512m

docker-compose down
docker-compose up -d
```
</details>

### ğŸ“‹ Health Check Commands

```bash
# Full system health check
./scripts/health-check.sh

# Individual service logs
docker-compose logs -f [service-name]

# Service restart
docker-compose restart [service-name]
```

---

## ğŸ“š Documentation

### ğŸ¯ Key Endpoints

```bash
# Rate Providers
GET  http://localhost:8080/rates/current    # REST provider rates
GET  http://localhost:8080/actuator/health  # REST provider health

# Main Application  
GET  http://localhost:8082/actuator/health  # Main app health
GET  http://localhost:8082/metrics          # Application metrics

# Infrastructure
GET  http://localhost:9200/_cluster/health  # OpenSearch cluster
GET  http://localhost:5601/api/status       # Kibana status
```

### ğŸ—ï¸ Project Structure

```
toyota-forex-system/
â”œâ”€â”€ ğŸ“‚ data-providers/
â”‚   â”œâ”€â”€ rest-rate-provider/     # HTTP API rate provider
â”‚   â””â”€â”€ tcp-rate-provider/      # TCP socket rate provider
â”œâ”€â”€ ğŸ“‚ main-application/        # Core processing engine
â”œâ”€â”€ ğŸ“‚ kafka-consumer/          # PostgreSQL persistence
â”œâ”€â”€ ğŸ“‚ kafka-consumer-opensearch/ # OpenSearch indexing
â”œâ”€â”€ ğŸ“‚ filebeat/               # Log aggregation config
â”œâ”€â”€ ğŸ“‚ postgres-init-scripts/  # Database initialization
â”œâ”€â”€ ğŸ“‚ logs/                   # Application logs
â”œâ”€â”€ ğŸ³ docker-compose.yml      # Service orchestration
â””â”€â”€ ğŸ“‹ .env                    # Environment configuration
```

### ğŸ”— Related Documentation

- [Kafka Topics & Message Formats](./docs/kafka-topics.md)
- [Database Schema](./docs/database-schema.md)
- [API Documentation](./docs/api-documentation.md)
- [Pipeline Processing Logic](./docs/pipeline-processing.md)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- Built with modern microservices architecture
- Leverages enterprise-grade technologies
- Designed for scalability and maintainability

---

<div align="center">

**â­ Star this repository if you find it helpful!**

Made with â¤ï¸ for real-time data processing
email : f.karatash.dev@gmail.com

</div>